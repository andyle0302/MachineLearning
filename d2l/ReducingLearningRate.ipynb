{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReducingLearningRate.ipynb",
      "provenance": [],
      "mount_file_id": "1uiZQPNZZ4X3AxF-FzmHiBgLqrZbiNnub",
      "authorship_tag": "ABX9TyP6YutJ7JBTwedkIAYvaYgo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qtuter1997/MachineLearning/blob/main/d2l/ReducingLearningRate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2l32UJqC1TE"
      },
      "source": [
        "**Learning rate schedule and Adaptive learning rate methods for Deep Learning**\n",
        "\n",
        "---\n",
        "The most of methods to optimal model when train deep neural network is use reduce learning rate.\n",
        "\n",
        "1. Learning Rate schedules\n",
        "2. Adaptive learning rate methods\n",
        "\n",
        "Reference tutorial at [here](https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1).\n",
        "\n",
        "In this tutorial, i train convolutional neural network on [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) using differing learning rate schedules and adaptive learing rate methods to compare their model performance.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjnvmY7zG-Td"
      },
      "source": [
        "1. Learning rate schedules\n",
        "\n",
        "Reducing the learning rate according to a pre-defined schedule.\n",
        "\n",
        "  Common learning rate schdules include **time-base decay, step decay** and **exponential decay**.\n",
        "  \n",
        "*   Constant learning rate\n",
        "*   Time-base dacay\n",
        "*   Step decay\n",
        "*   Exponential decay\n",
        "\n",
        "In the first half of this tutorial\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PIEapBJUCxMi",
        "outputId": "cbe82dde-ef5f-41f0-efc3-d0a0cb8adaa4"
      },
      "source": [
        "# Add library\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD, Adam, Adagrad, Adadelta, RMSprop\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH6KoaGJQpYB"
      },
      "source": [
        "Load CIFAR10 data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGoUvFFRQnR7",
        "outputId": "f8a0e902-7439-4e51-cb6a-8538dac3f738"
      },
      "source": [
        "batch_size = 64 # 2^x to match GPU\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "\n",
        "# input image demensions\n",
        "img_row, img_col = 32, 32\n",
        "\n",
        "# The data, shuffled and split between train and test sets\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "X_train.shape, Y_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1art_RGSs9E",
        "outputId": "fd8f74b6-3c0f-477c-987c-bff81ae7a0ea"
      },
      "source": [
        "# In example, we only use cat [==3] and dog [==5]\n",
        "train_picks = np.ravel(np.logical_or(Y_train == 3, Y_train == 5))\n",
        "test_picks = np.ravel(np.logical_or(Y_test == 3, Y_test == 5))\n",
        "print(train_picks)\n",
        "Y_train = np.array(Y_train[train_picks] == 5, dtype= int)\n",
        "Y_test = np.array(Y_test[test_picks] == 5, dtype= int)\n",
        "\n",
        "X_train = X_train[train_picks]\n",
        "X_test = X_test[test_picks]\n",
        "\n",
        "if backend.image_data_format() == 'channels_first':\n",
        "  X_train = X_train.reshape(X_train.shape[0], 3, img_row, img_col)\n",
        "  X_test = X_test.reshape(X_test.shape[0], 3, img_row, img_col)\n",
        "  input_shape = (3, img_row, img_col)\n",
        "else:\n",
        "  X_train = X_train.reshape(X_train.shape[0], img_row, img_col, 3)\n",
        "  X_test = X_test.reshape(X_test.shape[0], img_row, img_col, 3)\n",
        "  input_shape = (img_row, img_col, 3)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "Y_train = to_categorical(np.ravel(Y_train), num_classes)\n",
        "Y_test = to_categorical(np.ravel(Y_test), num_classes)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False False False ... False False False]\n",
            "X_train shape: (10000, 32, 32, 3)\n",
            "10000 train samples\n",
            "2000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s35bRk7hT7j"
      },
      "source": [
        "Define function to construct CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db854VqmRzGf"
      },
      "source": [
        "def cnn_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape= input_shape))\n",
        "  model.add\n",
        "  model.add"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMxl4Ox3LlHN"
      },
      "source": [
        "2. Adaptive learning rate methods"
      ]
    }
  ]
}